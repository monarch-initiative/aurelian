
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.15">
    
    
      
        <title>PaperQA Example - Aurelian</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../css/jupyter-cells.css">
    
      <link rel="stylesheet" href="../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="pink">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#paperqa-with-aurelian" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Aurelian" class="md-header__button md-logo" aria-label="Aurelian" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Aurelian
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              PaperQA Example
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="pink"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue" data-md-color-accent="amber"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Aurelian" class="md-nav__button md-logo" aria-label="Aurelian" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Aurelian
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Agents
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Agents
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/amigo_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    amigo_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/biblio_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    biblio_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/checklist_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    checklist_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/chemistry_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    chemistry_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/d4d_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    d4d_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/diagnosis_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    diagnosis_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/gene_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    gene_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/goann_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    goann_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/gocam_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    gocam_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/linkml_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    linkml_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/monarch_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    monarch_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/ontology_mapper_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ontology_mapper_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/phenopacket_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    phenopacket_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/rag_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    rag_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/ubergraph_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    ubergraph_agent
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../agents/uniprot_agent/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    uniprot_agent
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cli/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Command Line
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mcp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MCP Integration
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Integrations
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Integrations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../integrations/goose.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Goose
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../goose/using-talisman-mcp.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Talisman with Goose
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Terpenoids/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Chemistry
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GO-CAM-Reviews/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GO-CAM-Reviews
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../GO-CAM-Drawings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GO-CAM-Drawings
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../test_results.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Test Results
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#initialize-the-paperqa-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Initialize the PaperQA Agent
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-papers-to-the-collection" class="md-nav__link">
    <span class="md-ellipsis">
      Adding Papers to the Collection
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#understanding-the-paperqa-workflow" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding the PaperQA Workflow
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#searching-for-papers" class="md-nav__link">
    <span class="md-ellipsis">
      Searching for Papers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#querying-papers-to-answer-questions" class="md-nav__link">
    <span class="md-ellipsis">
      Querying Papers to Answer Questions
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-the-agent-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Using the Agent Interface
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      Cleanup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#running-the-paperqa-agent-ui" class="md-nav__link">
    <span class="md-ellipsis">
      Running the PaperQA Agent UI
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script>
(function() {
  function addWidgetsRenderer() {
    var requireJsScript = document.createElement('script');
    requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js';

    var mimeElement = document.querySelector('script[type="application/vnd.jupyter.widget-view+json"]');
    var jupyterWidgetsScript = document.createElement('script');
    var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js';
    var widgetState;

    // Fallback for older version:
    try {
      widgetState = mimeElement && JSON.parse(mimeElement.innerHTML);

      if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) {
        widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js';
      }
    } catch(e) {}

    jupyterWidgetsScript.src = widgetRendererSrc;

    document.body.appendChild(requireJsScript);
    document.body.appendChild(jupyterWidgetsScript);
  }

  document.addEventListener('DOMContentLoaded', addWidgetsRenderer);
}());
</script>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="paperqa-with-aurelian">PaperQA with Aurelian</h1>
<p>This notebook demonstrates how to use the Aurelian PaperQA integration to search, analyze, and query scientific papers. The PaperQA agent allows you to:</p>
<ol>
<li>Search for papers on specific topics</li>
<li>Add papers to your collection from files or URLs</li>
<li>Query papers to answer scientific questions</li>
<li>List papers in your collection</li>
</ol>
<h2 id="setup">Setup</h2>
<p>First, let's load any environment variables and set up the agent.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">dotenv</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="n">load_dotenv</span><span class="p">(</span><span class="s2">&quot;../../.env&quot;</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>True</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">nest_asyncio</span>
<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span>
</code></pre></div>

</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="initialize-the-paperqa-agent">Initialize the PaperQA Agent</h2>
<p>Now we'll import and initialize the PaperQA agent with custom settings.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tempfile</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aurelian.agents.paperqa.paperqa_agent</span><span class="w"> </span><span class="kn">import</span> <span class="n">paperqa_agent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aurelian.agents.paperqa.paperqa_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_config</span>

<span class="c1"># Create a temporary directory for our papers</span>
<span class="n">temp_dir</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">mkdtemp</span><span class="p">()</span>
<span class="n">papers_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">temp_dir</span><span class="p">,</span> <span class="s2">&quot;papers&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">papers_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Configure the agent</span>
<span class="n">paperqa_config</span> <span class="o">=</span> <span class="n">get_config</span><span class="p">()</span>
<span class="n">paperqa_config</span><span class="o">.</span><span class="n">paper_directory</span> <span class="o">=</span> <span class="n">papers_dir</span>

<span class="c1"># Optionally customize other settings</span>
<span class="n">paperqa_config</span><span class="o">.</span><span class="n">llm</span> <span class="o">=</span> <span class="s2">&quot;gpt-4o-2024-11-20&quot;</span>  <span class="c1"># Or any other supported model</span>
<span class="n">paperqa_config</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="s2">&quot;text-embedding-3-small&quot;</span>  <span class="c1"># Default embedding model</span>
<span class="n">paperqa_config</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.2</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Papers will be stored in: </span><span class="si">{</span><span class="n">papers_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Papers will be stored in: /var/folders/_h/52yfmvlj0ylc1jxpx9tv_j8w0000gn/T/tmptekicdt3/papers
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="adding-papers-to-the-collection">Adding Papers to the Collection</h2>
<p>You can add papers to your collection either from local files or from URLs. Let's add a paper from a URL. </p>
<p>&gt; <strong>Note</strong>: When using URLs, make sure it's a direct link to a PDF file (ending with .pdf).</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Let&#39;s use the add_paper function directly</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aurelian.agents.paperqa.paperqa_tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">add_paper</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic_ai</span><span class="w"> </span><span class="kn">import</span> <span class="n">RunContext</span>

<span class="c1"># Create a run context with our config</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">RunContext</span><span class="p">(</span><span class="n">deps</span><span class="o">=</span><span class="n">paperqa_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">usage</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># Add a paper from a URL with auto_index=True to automatically build the index</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://arxiv.org/pdf/2203.06566.pdf&quot;</span>  <span class="c1"># PaperQA paper</span>
<span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">add_paper</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">auto_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">result</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Downloaded https://arxiv.org/pdf/2203.06566.pdf to /var/folders/_h/52yfmvlj0ylc1jxpx9tv_j8w0000gn/T/tmptekicdt3/papers/2203.06566.pdf
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>
<code>CROSSREF_MAILTO environment variable not set. Crossref API rate limits may apply.
CROSSREF_API_KEY environment variable not set. Crossref API rate limits may apply.
SEMANTIC_SCHOLAR_API_KEY environment variable not set. Semantic Scholar API rate limits may apply.
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Building index for 1 PDF files in /var/folders/_h/52yfmvlj0ylc1jxpx9tv_j8w0000gn/T/tmptekicdt3/papers...
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_subarea output_stream output_stderr output_text">
<pre>
<code>SEMANTIC_SCHOLAR_API_KEY environment variable not set. Semantic Scholar API rate limits may apply.
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>{'success': True,
 'docname': 'Wu2022',
 'doc': None,
 'index_result': {'success': True,
  'paper_directory': '/var/folders/_h/52yfmvlj0ylc1jxpx9tv_j8w0000gn/T/tmptekicdt3/papers',
  'pdf_files_count': 1,
  'indexed_papers_count': 1,
  'indexed_papers': ['2203.06566.pdf'],
  'message': 'Successfully indexed 1 papers out of 1 PDF files.'},
 'message': 'Paper added and indexed successfully. 1 papers now in the index.'}</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="understanding-the-paperqa-workflow">Understanding the PaperQA Workflow</h2>
<p>PaperQA has a specific workflow for managing papers:</p>
<ol>
<li><strong>Adding papers</strong>: When you add a paper with <code>add_paper()</code>, it:</li>
<li>Downloads the PDF if it's a URL (must be a direct PDF link)</li>
<li>Saves the PDF to the paper directory</li>
<li>
<p>Processes the paper with PaperQA</p>
</li>
<li>
<p><strong>Indexing papers</strong>: For papers to be searchable, they need to be indexed:</p>
</li>
<li>By default, <code>add_paper()</code> has <code>auto_index=True</code> which automatically builds the index</li>
<li>For adding multiple papers, you can set <code>auto_index=False</code> and then manually call <code>build_index()</code></li>
<li>
<p>You can also use the CLI command: <code>aurelian paperqa index</code></p>
</li>
<li>
<p><strong>Listing papers</strong>: The <code>list_papers()</code> function shows both:</p>
</li>
<li>PDF files found in the paper directory </li>
<li>Papers that have been successfully indexed</li>
</ol>
<p>Let's list the papers to see what's in our collection:</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Let&#39;s rebuild the index to make our paper searchable</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aurelian.agents.paperqa.paperqa_tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_index</span>

<span class="n">index_result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">build_index</span><span class="p">(</span><span class="n">ctx</span><span class="p">)</span>
<span class="n">index_result</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Building index for 1 PDF files in /var/folders/_h/52yfmvlj0ylc1jxpx9tv_j8w0000gn/T/tmptekicdt3/papers...
</code>
</pre>
</div>
</div>
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>{'success': True,
 'paper_directory': '/var/folders/_h/52yfmvlj0ylc1jxpx9tv_j8w0000gn/T/tmptekicdt3/papers',
 'pdf_files_count': 1,
 'indexed_papers_count': 1,
 'indexed_papers': ['2203.06566.pdf'],
 'message': 'Successfully indexed 1 papers out of 1 PDF files.'}</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="searching-for-papers">Searching for Papers</h2>
<p>Now let's search for papers related to a specific topic.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Search for papers about question answering</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aurelian.agents.paperqa.paperqa_tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">search_papers</span>

<span class="n">search_results</span> <span class="o">=</span> <span class="k">await</span> <span class="n">search_papers</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="s2">&quot;question answering with scientific papers&quot;</span><span class="p">)</span>
<span class="n">search_results</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>AnswerResponse(session=PQASession(id=UUID('18c2c191-7477-4c53-912e-e9139da870d7'), question='Find scientific papers about: question answering with scientific papers', answer="PromptChainer is a visual programming tool designed to facilitate the creation of complex, multi-step workflows using large language models (LLMs). It enables users to chain multiple LLM prompts, where the output of one step serves as the input for the next. This approach is particularly useful for tasks such as question answering with scientific papers, where a single prompt is often insufficient to handle the complexity of the task. Users can visually design and test workflows that include steps like extracting, classifying, and summarizing information from academic texts (wu2022promptchainerchaininglarge pages 9-10).\n\nPromptChainer supports modular and interpretable pipelines, allowing users to customize workflows for unstructured queries. For example, it can be used to process scientific paper queries by chaining steps such as entity extraction, query formatting, and summarization. This modularity enables the system to handle diverse tasks, including parsing lists, extracting entities, and formatting responses (wu2022promptchainerchaininglarge pages 3-3).\n\nThe tool's flexibility is demonstrated through user-created chains averaging 5.5 nodes, which often include pre-defined helper nodes for tasks like categorizing inputs and reorganizing data. These features make PromptChainer a valuable tool for prototyping AI-driven applications in scientific domains (wu2022promptchainerchaininglarge pages 5-6).", answer_reasoning=None, has_successful_answer=True, context="wu2022promptchainerchaininglarge pages 1-1: The excerpt introduces PromptChainer, a visual programming interface designed to help users chain multiple large language model (LLM) prompts together. This chaining allows the output of one LLM run to become the input for the next, enabling users to accomplish complex tasks that cannot be handled by a single LLM prompt. The authors note that while LLMs like GPT-3 have made rapid prototyping possible, real-world applications often require more complex workflows. PromptChainer addresses user needs such as transforming data between steps and debugging at multiple granularities, making it easier for non-AI experts to prototype AI-infused applications.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 1-2: The excerpt discusses how non-ML experts are increasingly able to use large language models (LLMs) for tasks such as question answering, code generation, and creative writing by leveraging prompt-based prototyping. This approach allows users to bypass the traditional, resource-intensive process of collecting data and training models. However, for complex or multi-step tasks (e.g., a chatbot that must first classify a query before generating a response), a single LLM prompt is often insufficient. To address this, the authors propose 'chaining' multiple LLM runs, where each step in a complex task is handled by a separate, targeted prompt, and outputs are passed between steps. The PromptChainer interface supports this process by allowing users to visually design, edit, and test these chains of prompts.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 5-6: The excerpt discusses how users employed PromptChainer to build diverse chains for various tasks, including question answering, chatbots, ad generation, and writing assistants. Users leveraged chaining to overcome single-prompt limitations and make prototypes extensible. Most chaining needs were met using pre-defined helper nodes rather than custom JavaScript, with chains averaging 5.5 nodes. The chains often included nodes for categorizing inputs, sourcing information from the LLM, and reorganizing input. Example chains included extracting and classifying entities, formatting queries, and calling external APIs, demonstrating the tool's flexibility for complex, multi-step tasks such as those found in scientific question answering.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 9-10: The excerpt describes PromptChainer, a visual programming tool for chaining large language model (LLM) prompts to create complex, multi-step workflows. It provides examples of user study chains, such as a music chatbot that responds to unstructured statements about music, an ads generator that creates editorial blurbs from review attributes, and a writing assistant that generates full stories from character descriptions. The system allows users to visually compose and connect different prompt modules, enabling tasks like classifying entities, generating descriptions, and summarizing long essays. This approach can facilitate question answering with scientific papers by allowing users to build custom chains for extracting, classifying, and summarizing information from academic texts.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 3-3: The excerpt describes PromptChainer, a system that enables users to chain large language model prompts through a visual programming interface. The system is designed to help users quickly create low-fidelity prototypes for tasks such as question answering, parsing lists, extracting entities, and formatting responses. The example provided shows a music chatbot workflow, where user input is processed through various steps like checking music relevance, extracting artist names, calling APIs, and filtering toxic responses. This approach allows for modular, interpretable, and customizable pipelines for handling unstructured queries, such as those encountered in scientific paper question answering.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nValid Keys: wu2022promptchainerchaininglarge pages 1-1, wu2022promptchainerchaininglarge pages 1-2, wu2022promptchainerchaininglarge pages 5-6, wu2022promptchainerchaininglarge pages 9-10, wu2022promptchainerchaininglarge pages 3-3", contexts=[Context(context='The excerpt describes PromptChainer, a visual programming tool for chaining large language model (LLM) prompts to create complex, multi-step workflows. It provides examples of user study chains, such as a music chatbot that responds to unstructured statements about music, an ads generator that creates editorial blurbs from review attributes, and a writing assistant that generates full stories from character descriptions. The system allows users to visually compose and connect different prompt modules, enabling tasks like classifying entities, generating descriptions, and summarizing long essays. This approach can facilitate question answering with scientific papers by allowing users to build custom chains for extracting, classifying, and summarizing information from academic texts.', question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 9-10', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=9), Context(context='The excerpt describes PromptChainer, a system that enables users to chain large language model prompts through a visual programming interface. The system is designed to help users quickly create low-fidelity prototypes for tasks such as question answering, parsing lists, extracting entities, and formatting responses. The example provided shows a music chatbot workflow, where user input is processed through various steps like checking music relevance, extracting artist names, calling APIs, and filtering toxic responses. This approach allows for modular, interpretable, and customizable pipelines for handling unstructured queries, such as those encountered in scientific paper question answering.', question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 3-3', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context="The excerpt discusses PromptChainer, a visual programming tool designed to help users chain large language model (LLM) prompts. The authors identify three unique challenges in authoring LLM chains due to the models' versatile and open-ended nature. PromptChainer aids users in transforming intermediate LLM outputs and debugging chains, especially when LLM steps interact in complex ways. The study suggests future improvements, such as supporting more complex chains and enabling users to sketch chain structures without extensive upfront prompting. These features are relevant for scientific paper question answering, as they facilitate the construction and debugging of multi-step reasoning chains required for extracting and synthesizing information from scientific texts.", question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 7-9', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context="The excerpt discusses how users employed PromptChainer to build diverse chains for various tasks, including question answering, chatbots, ad generation, and writing assistants. Users leveraged chaining to overcome single-prompt limitations and make prototypes extensible. Most chaining needs were met using pre-defined helper nodes rather than custom JavaScript, with chains averaging 5.5 nodes. The chains often included nodes for categorizing inputs, sourcing information from the LLM, and reorganizing input. Example chains included extracting and classifying entities, formatting queries, and calling external APIs, demonstrating the tool's flexibility for complex, multi-step tasks such as those found in scientific question answering.", question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 5-6', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=9), Context(context='The excerpt discusses challenges and limitations encountered when chaining large language model (LLM) prompts for complex tasks using PromptChainer, a visual programming tool. Specifically, it highlights issues with coherence in outputs when parallel tasks are interdependent but not coordinated, as seen in a story-writing example where independently generated paragraphs led to an incoherent narrative. Users sometimes had to manually track outputs to maintain context. The authors suggest future work should address inter-dependency between parallel sub-tasks and improve tracing and visualization of data flow through the prompt chains, which could be beneficial for tasks like question answering with scientific papers that require maintaining context and coherence across multiple steps.', question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 6-7', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context='The excerpt discusses how participants in the PromptChainer study were asked to pre-create prompts for sub-tasks, which may have led them to become invested in their initial prompt chains and less likely to consider alternative structures. Prior research suggests that considering multiple alternatives (parallel prototyping) can yield better outcomes. The authors suggest that future work could encourage users to rapidly prototype multiple possible prompt chains by creating simple or incomplete prompts for each step, allowing for quick feasibility testing without significant time investment. PromptChainer could facilitate this by encouraging minimal initial examples or zero-shot prompts. The excerpt also notes that users may have chosen tasks that were easy to decompose due to time constraints, and suggests exploring strategies for decomposing more complex tasks in future work.', question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 7-7', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context="The excerpt discusses how non-ML experts are increasingly able to use large language models (LLMs) for tasks such as question answering, code generation, and creative writing by leveraging prompt-based prototyping. This approach allows users to bypass the traditional, resource-intensive process of collecting data and training models. However, for complex or multi-step tasks (e.g., a chatbot that must first classify a query before generating a response), a single LLM prompt is often insufficient. To address this, the authors propose 'chaining' multiple LLM runs, where each step in a complex task is handled by a separate, targeted prompt, and outputs are passed between steps. The PromptChainer interface supports this process by allowing users to visually design, edit, and test these chains of prompts.", question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 1-2', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=9), Context(context='The excerpt discusses how users interact with PromptChainer, a visual programming tool for chaining large language model (LLM) prompts. Users debugged their chains by running them end-to-end and then isolating issues to specific LLM nodes, using features like breakpoints and independent testing blocks. The study found that even experienced users refined their prompts during chain authoring. Key challenges identified include ensuring coherence between interdependent sub-tasks and managing complex logic in chains, especially when tasks run in parallel, which can decrease overall coherence.', question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 6-6', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context='PromptChainer is a visual programming tool designed to facilitate the chaining of large language model (LLM) prompts. It uses a node-edge interface where each node represents a step in the chain, and nodes can have named inputs and outputs that connect them. The system automatically synchronizes input names with prompt placeholders, ensuring consistency across the chain. PromptChainer provides features for debugging at multiple levels, including unit testing individual nodes, end-to-end chain assessment, and breakpoint debugging to isolate errors. User studies showed that PromptChainer supports building complex chains for tasks like ads generation and writing assistance, using patterns such as parallel logic branches and iterative content development.', question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 4-5', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context='The excerpt introduces PromptChainer, a visual programming interface designed to help users chain multiple large language model (LLM) prompts together. This chaining allows the output of one LLM run to become the input for the next, enabling users to accomplish complex tasks that cannot be handled by a single LLM prompt. The authors note that while LLMs like GPT-3 have made rapid prototyping possible, real-world applications often require more complex workflows. PromptChainer addresses user needs such as transforming data between steps and debugging at multiple granularities, making it easier for non-AI experts to prototype AI-infused applications.', question='question answering with scientific papers', text=Text(text='', name='wu2022promptchainerchaininglarge pages 1-1', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=9)], references='1. (wu2022promptchainerchaininglarge pages 5-6): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n2. (wu2022promptchainerchaininglarge pages 9-10): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n3. (wu2022promptchainerchaininglarge pages 3-3): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.', formatted_answer="Question: Find scientific papers about: question answering with scientific papers\n\nPromptChainer is a visual programming tool designed to facilitate the creation of complex, multi-step workflows using large language models (LLMs). It enables users to chain multiple LLM prompts, where the output of one step serves as the input for the next. This approach is particularly useful for tasks such as question answering with scientific papers, where a single prompt is often insufficient to handle the complexity of the task. Users can visually design and test workflows that include steps like extracting, classifying, and summarizing information from academic texts (wu2022promptchainerchaininglarge pages 9-10).\n\nPromptChainer supports modular and interpretable pipelines, allowing users to customize workflows for unstructured queries. For example, it can be used to process scientific paper queries by chaining steps such as entity extraction, query formatting, and summarization. This modularity enables the system to handle diverse tasks, including parsing lists, extracting entities, and formatting responses (wu2022promptchainerchaininglarge pages 3-3).\n\nThe tool's flexibility is demonstrated through user-created chains averaging 5.5 nodes, which often include pre-defined helper nodes for tasks like categorizing inputs and reorganizing data. These features make PromptChainer a valuable tool for prototyping AI-driven applications in scientific domains (wu2022promptchainerchaininglarge pages 5-6).\n\nReferences\n\n1. (wu2022promptchainerchaininglarge pages 5-6): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n2. (wu2022promptchainerchaininglarge pages 9-10): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n3. (wu2022promptchainerchaininglarge pages 3-3): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n", graded_answer=None, cost=0.048065, token_counts={'gpt-4o-2024-11-20': [4938, 352], 'gpt-4.1-2025-04-14': [10220, 1470]}, config_md5='c2d3871e0896fb4978bab71fc7a64da5', tool_history=[['paper_search'], ['gather_evidence'], ['gen_answer'], ['complete']], used_contexts={'wu2022promptchainerchaininglarge pages 3-3', 'wu2022promptchainerchaininglarge pages 5-6', 'wu2022promptchainerchaininglarge pages 9-10'}), bibtex=None, status=&lt;AgentStatus.SUCCESS: 'success'&gt;, timing_info=None, duration=0.0, stats=None)</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="querying-papers-to-answer-questions">Querying Papers to Answer Questions</h2>
<p>Now let's ask a question about the papers in our collection.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Query papers to answer a question</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">aurelian.agents.paperqa.paperqa_tools</span><span class="w"> </span><span class="kn">import</span> <span class="n">query_papers</span>

<span class="n">answer</span> <span class="o">=</span> <span class="k">await</span> <span class="n">query_papers</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="s2">&quot;What are the main challenges in question answering with scientific literature?&quot;</span><span class="p">)</span>
<span class="n">answer</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_text output_subarea output_execute_result">
<pre>
<code>AnswerResponse(session=PQASession(id=UUID('d40dfa1b-3adc-4544-a06f-eb97924846f9'), question='What are the main challenges in question answering with scientific literature?', answer='Question answering with scientific literature presents several challenges, particularly when leveraging large language models (LLMs). One major issue is the need to decompose complex tasks into multiple sub-tasks, each requiring separate LLM prompts. This chaining approach increases transparency and control but introduces difficulties in designing and coordinating prompts, managing information flow between steps, and efficiently prototyping applications (wu2022promptchainerchaininglarge pages 1-2). \n\nErrors in one step can propagate through the chain, leading to cascading failures that hinder accurate results. Debugging such chains is particularly challenging due to the black-box nature of LLMs and the interdependencies between prompts (wu2022promptchainerchaininglarge pages 2-3, wu2022promptchainerchaininglarge pages 4-5). Additionally, maintaining logical consistency across interdependent tasks is difficult, especially when outputs from parallel tasks are not well-coordinated (wu2022promptchainerchaininglarge pages 6-7).\n\nUsers also face challenges in transforming data between steps, tracking how information flows through the chain, and mapping outputs back to original inputs. This complexity can overwhelm users, particularly non-experts, and necessitates tools for better tracing, visualization, and debugging (wu2022promptchainerchaininglarge pages 1-1, wu2022promptchainerchaininglarge pages 6-7). Tools like PromptChainer aim to address these issues by providing visual programming interfaces and features such as automated updates, unit testing, and breakpoint debugging (wu2022promptchainerchaininglarge pages 4-5).', answer_reasoning=None, has_successful_answer=True, context='wu2022promptchainerchaininglarge pages 2-3: The excerpt discusses several challenges in leveraging large language models (LLMs) for complex tasks like question answering with scientific literature. Key challenges include: (1) the overhead of fully utilizing LLM capabilities, as users must design both individual prompts and the overall task decomposition; (2) the risk of inadvertently introducing errors when chaining prompts, which can lead to cascading errors due to the black-box and unstable nature of LLM outputs; and (3) the complexity of debugging interactions between multiple prompts, especially for tasks with high interdependency or logical complexity. The need for targeted tooling and scaffolding to help users build mental models, handle diverse data formats, and debug errors is emphasized.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 1-1: The excerpt discusses how large language models (LLMs) enable rapid prototyping of machine learning functionalities, but many real-world applications—such as question answering with scientific literature—involve complex tasks that cannot be handled by a single LLM run. Chaining multiple LLM runs, where the output of one step becomes the input to the next, can help address these complex tasks. However, challenges remain in authoring such chains, especially for non-AI experts. Users need support for transforming data between steps and debugging chains at multiple granularities. Tools like PromptChainer aim to lower these barriers by providing visual programming interfaces for chaining prompts.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 1-2: The excerpt discusses challenges in using large language models (LLMs) for complex, multi-step tasks such as question answering with scientific literature. While LLMs can be prompted for various tasks by non-ML experts, many real-world applications require decomposing tasks into multiple, targeted sub-tasks, each handled by a separate LLM prompt. This chaining approach increases transparency and control but introduces new challenges: users must design and coordinate multiple prompts, manage the flow of information between steps, and prototype realistic applications efficiently. Supporting users in authoring these chains remains an open problem, especially for non-experts.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 4-5: The excerpt discusses challenges in building and debugging chains of prompts for large language models (LLMs) using PromptChainer, a visual programming tool. Key challenges include maintaining consistency when node inputs/outputs change, addressing cascading errors where an error in one node affects downstream nodes, and providing transparency in how data flows through the chain. PromptChainer addresses these by automatically updating node handles, supporting unit and end-to-end testing, and enabling breakpoint debugging to isolate and fix errors. These challenges are relevant to question answering with scientific literature, where complex, multi-step reasoning and error propagation can hinder accurate answers.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nwu2022promptchainerchaininglarge pages 6-7: The excerpt discusses challenges in chaining large language model (LLM) prompts for complex tasks, such as question answering with scientific literature. Key issues include decreased coherence when parallel tasks are interdependent but not coordinated, as seen when independently generated text segments fail to maintain logical consistency. Tracking complex decompositions can become overwhelming, making it difficult to trace how information flows through the chain of prompts. Users may struggle to map outputs back to original inputs, especially when multiple entities or steps are involved. The authors suggest that improved tracing, chain grouping, and execution visualizations could help address these challenges.\nFrom Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\nValid Keys: wu2022promptchainerchaininglarge pages 2-3, wu2022promptchainerchaininglarge pages 1-1, wu2022promptchainerchaininglarge pages 1-2, wu2022promptchainerchaininglarge pages 4-5, wu2022promptchainerchaininglarge pages 6-7', contexts=[Context(context='The excerpt identifies three unique challenges in authoring chains of large language model (LLM) prompts, which are relevant to question answering with scientific literature. These challenges stem from the versatile and open-ended nature of LLMs. Specifically, users face difficulties in transforming intermediate LLM outputs, debugging chains when LLM steps interact in complex ways, and constructing chains without investing excessive time upfront. The study suggests that tools like PromptChainer can help users manage these challenges by enabling easier transformation and debugging of LLM outputs, and by supporting the sketching of chain structures before full development.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 7-9', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context='The excerpt discusses challenges in using large language models (LLMs) for complex, multi-step tasks such as question answering with scientific literature. While LLMs can be prompted for various tasks by non-ML experts, many real-world applications require decomposing tasks into multiple, targeted sub-tasks, each handled by a separate LLM prompt. This chaining approach increases transparency and control but introduces new challenges: users must design and coordinate multiple prompts, manage the flow of information between steps, and prototype realistic applications efficiently. Supporting users in authoring these chains remains an open problem, especially for non-experts.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 1-2', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context='The excerpt discusses how large language models (LLMs) enable rapid prototyping of machine learning functionalities, but many real-world applications—such as question answering with scientific literature—involve complex tasks that cannot be handled by a single LLM run. Chaining multiple LLM runs, where the output of one step becomes the input to the next, can help address these complex tasks. However, challenges remain in authoring such chains, especially for non-AI experts. Users need support for transforming data between steps and debugging chains at multiple granularities. Tools like PromptChainer aim to lower these barriers by providing visual programming interfaces for chaining prompts.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 1-1', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context='The excerpt discusses several challenges in leveraging large language models (LLMs) for complex tasks like question answering with scientific literature. Key challenges include: (1) the overhead of fully utilizing LLM capabilities, as users must design both individual prompts and the overall task decomposition; (2) the risk of inadvertently introducing errors when chaining prompts, which can lead to cascading errors due to the black-box and unstable nature of LLM outputs; and (3) the complexity of debugging interactions between multiple prompts, especially for tasks with high interdependency or logical complexity. The need for targeted tooling and scaffolding to help users build mental models, handle diverse data formats, and debug errors is emphasized.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 2-3', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=9), Context(context="The excerpt from  describes the use of PromptChainer, a visual programming tool for chaining large language model prompts to build complex workflows, such as a music chatbot. The workflow includes steps like inputting utterances, branching based on relevance, extracting entities, calling APIs, formatting responses, and filtering for toxicity. The tool aims to help users quickly prototype and iterate on prompt chains, finding a 'sweet spot' for effective prompting. While the excerpt does not directly address question answering with scientific literature, it highlights challenges in structuring prompts, parsing responses, extracting relevant entities, and ensuring factual and non-toxic outputs—issues that are also relevant to scientific question answering.", question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 3-3', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=6), Context(context='The excerpt from  describes PromptChainer, a system for chaining large language model prompts through visual programming, and illustrates various use cases such as music chatbots, ads generators, and writing assistants. While the text does not directly address question answering with scientific literature, it implies challenges related to parsing complex information, classifying entities, extracting relevant data, and generating coherent responses from unstructured or lengthy texts. The visual programming approach aims to make these processes more transparent and controllable, suggesting that key challenges include managing information flow, ensuring accurate extraction and classification, and maintaining context across chained prompts.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 9-10', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=6), Context(context='The excerpt discusses challenges in chaining large language model (LLM) prompts for complex tasks, such as question answering with scientific literature. Key issues include decreased coherence when parallel tasks are interdependent but not coordinated, as seen when independently generated text segments fail to maintain logical consistency. Tracking complex decompositions can become overwhelming, making it difficult to trace how information flows through the chain of prompts. Users may struggle to map outputs back to original inputs, especially when multiple entities or steps are involved. The authors suggest that improved tracing, chain grouping, and execution visualizations could help address these challenges.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 6-7', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8), Context(context='The excerpt discusses challenges related to designing and testing prompt chains for large language models (LLMs) in systems like PromptChainer. One challenge is that participants, after pre-creating prompts for sub-tasks, may become invested in their initial designs, making them less likely to consider alternative chain structures or revise their prompts. This can limit exploration and innovation. The text suggests that encouraging users to rapidly prototype multiple prompt chains—using simple or partial prompts—could help test feasibility without heavy time investment. Additionally, users may select tasks that are easier to decompose due to time constraints, potentially overlooking more complex decomposition strategies needed for harder tasks.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 7-7', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=7), Context(context='The excerpt discusses the challenges faced by users when authoring chains of prompts for large language models (LLMs), particularly in the context of prototyping applications like chatbots. One key challenge is the versatility of LLMs, which requires users to develop a mental model of what the LLM can do. Additionally, LLMs often produce outputs in arbitrary string formats, making it difficult to process or transform these outputs for downstream tasks. This necessitates data transformation and filtering, often through helper nodes or custom functions, to ensure outputs are usable and relevant.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 3-4', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=7), Context(context='The excerpt discusses challenges in building and debugging chains of prompts for large language models (LLMs) using PromptChainer, a visual programming tool. Key challenges include maintaining consistency when node inputs/outputs change, addressing cascading errors where an error in one node affects downstream nodes, and providing transparency in how data flows through the chain. PromptChainer addresses these by automatically updating node handles, supporting unit and end-to-end testing, and enabling breakpoint debugging to isolate and fix errors. These challenges are relevant to question answering with scientific literature, where complex, multi-step reasoning and error propagation can hinder accurate answers.', question='What are the main challenges in question answering with scientific literature?', text=Text(text='', name='wu2022promptchainerchaininglarge pages 4-5', doc=DocDetails(docname='wu2022promptchainerchaininglarge', dockey='feb8c43c18a655f0', citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566.', fields_to_overwrite_from_metadata={'dockey', 'docname', 'citation', 'doc_id', 'key'}, key='wu2022promptchainerchaininglarge', bibtex='@article{wu2022promptchainerchaininglarge,\n    author = "Wu, Tongshuang and Jiang, Ellen and Donsbach, Aaron and Gray, Jeff and Molina, Alejandra and Terry, Michael and Cai, Carrie J",\n    title = "PromptChainer: Chaining Large Language Model Prompts through Visual Programming",\n    year = "2022",\n    journal = "CHI Conference on Human Factors in Computing Systems Extended Abstracts",\n    month = "Apr",\n    doi = "10.48550/arxiv.2203.06566",\n    url = "https://doi.org/10.48550/arxiv.2203.06566",\n    publisher = "ACM"\n}\n', authors=['Tongshuang Wu', 'Ellen Jiang', 'Aaron Donsbach', 'Jeff Gray', 'Alejandra Molina', 'Michael Terry', 'Carrie J Cai'], publication_date=datetime.datetime(2022, 4, 27, 0, 0), year=2022, volume=None, issue=None, issn=None, pages=None, journal='CHI Conference on Human Factors in Computing Systems Extended Abstracts', publisher='ACM', url='https://doi.org/10.1145/3491101.3519729', title='PromptChainer: Chaining Large Language Model Prompts through Visual Programming', citation_count=87, bibtex_type='article', source_quality=-1, is_retracted=None, doi='10.48550/arxiv.2203.06566', doi_url='https://doi.org/10.48550/arxiv.2203.06566', doc_id='feb8c43c18a655f0', file_location=None, license=None, pdf_url=None, other={'bibtex_source': ['self_generated'], 'indexed': {'date-parts': [[2025, 5, 9]], 'date-time': '2025-05-09T12:30:15Z', 'timestamp': 1746793815327}, 'publisher-location': 'New York, NY, USA', 'reference-count': 17, 'content-domain': {'domain': [], 'crossmark-restriction': False}, 'short-container-title': [], 'published-print': {'date-parts': [[2022, 4, 27]]}, 'DOI': '10.1145/3491101.3519729', 'type': 'proceedings-article', 'created': {'date-parts': [[2022, 4, 29]], 'date-time': '2022-04-29T16:49:48Z', 'timestamp': 1651250988000}, 'source': 'Crossref', 'is-referenced-by-count': 87, 'prefix': '10.1145', 'author': [{'given': 'Tongshuang', 'family': 'Wu', 'sequence': 'first', 'affiliation': [{'name': 'University of Washington, United States'}]}, {'given': 'Ellen', 'family': 'Jiang', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Aaron', 'family': 'Donsbach', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Jeff', 'family': 'Gray', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Alejandra', 'family': 'Molina', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Michael', 'family': 'Terry', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}, {'given': 'Carrie J', 'family': 'Cai', 'sequence': 'additional', 'affiliation': [{'name': 'Google Research, United States'}]}], 'member': '320', 'published-online': {'date-parts': [[2022, 4, 28]]}, 'reference': [{'key': 'e_1_3_2_2_1_1', 'volume-title': 'Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033', 'author': 'Betz Gregor', 'year': '2021', 'unstructured': 'Gregor Betz , Kyle Richardson , and Christian Voigt . 2021 . Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033 Gregor Betz, Kyle Richardson, and Christian Voigt. 2021. Thinking Aloud: Dynamic Context Generation Improves Zero-Shot Reasoning Performance of GPT-2. ArXiv preprint abs/2103.13033 (2021). https://arxiv.org/abs/2103.13033'}, {'key': 'e_1_3_2_2_2_1', 'unstructured': 'Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]  Rishi Bommasani Drew\xa0A. Hudson Ehsan Adeli Russ Altman Simran Arora Sydney von Arx Michael\xa0S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill Erik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji Annie Chen Kathleen Creel Jared\xa0Quincy Davis Dora Demszky Chris Donahue Moussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh Li Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman Shelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt Daniel\xa0E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain Dan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani Omar Khattab Pang\xa0Wei Kohd Mark Krass Ranjay Krishna Rohith Kuditipudi Ananya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent Xiang\xa0Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher\xa0D. Manning Suvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan Deepak Narayanan Ben Newman Allen Nie Juan\xa0Carlos Niebles Hamed Nilforoshan Julian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon\xa0Sung Park Chris Piech Eva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren Frieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh Shiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin Rohan Taori Armin\xa0W. Thomas Florian Tramèr Rose\xa0E. Wang William Wang Bohan Wu Jiajun Wu Yuhuai Wu Sang\xa0Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia Michael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou and Percy Liang. 2021. On the Opportunities and Risks of Foundation Models. arxiv:2108.07258\xa0[cs.LG]'}, {'key': 'e_1_3_2_2_3_1', 'volume-title': 'Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020', 'author': 'Brown B.', 'year': '2020', 'unstructured': 'Tom\xa0 B. Brown , Benjamin Mann , Nick Ryder , Melanie Subbiah , Jared Kaplan , Prafulla Dhariwal , Arvind Neelakantan , Pranav Shyam , Girish Sastry , Amanda Askell , Sandhini Agarwal , Ariel Herbert-Voss , Gretchen Krueger , Tom Henighan , Rewon Child , Aditya Ramesh , Daniel\xa0 M. Ziegler , Jeffrey Wu , Clemens Winter , Christopher Hesse , Mark Chen , Eric Sigler , Mateusz Litwin , Scott Gray , Benjamin Chess , Jack Clark , Christopher Berner , Sam McCandlish , Alec Radford , Ilya Sutskever , and Dario Amodei . 2020 . Language Models are Few-Shot Learners . In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020 , NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html Tom\xa0B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\xa0M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.). https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html'}, {'key': 'e_1_3_2_2_4_1', 'doi-asserted-by': 'publisher', 'DOI': '10.4018/joeuc.2010101904'}, {'key': 'e_1_3_2_2_5_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1015864.1015889'}, {'key': 'e_1_3_2_2_6_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/1879831.1879836'}, {'key': 'e_1_3_2_2_7_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1109/ACSSC.2018.8645073'}, {'key': 'e_1_3_2_2_8_1', 'volume-title': 'Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'author': 'Jiang Ellen', 'year': '2022', 'unstructured': 'Ellen Jiang , Kristen Olson , Edwin Toh , Alejandra Molina , Aaron Donsbach , Michael Terry , and Carrie\xa0 J. Cai . 2022 . Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems. Ellen Jiang, Kristen Olson, Edwin Toh, Alejandra Molina, Aaron Donsbach, Michael Terry, and Carrie\xa0J. Cai. 2022. Prompt-based Prototyping with Large Language Models. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.'}, {'key': 'e_1_3_2_2_9_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/2047196.2047202'}, {'key': 'e_1_3_2_2_11_1', 'volume-title': 'What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804', 'author': 'Liu Jiachang', 'year': '2021', 'unstructured': 'Jiachang Liu , Dinghan Shen , Yizhe Zhang , Bill Dolan , Lawrence Carin , and Weizhu Chen . 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 ( 2021 ). https://arxiv.org/abs/2101.06804 Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3?ArXiv preprint abs/2101.06804 (2021). https://arxiv.org/abs/2101.06804'}, {'key': 'e_1_3_2_2_12_1', 'volume-title': 'Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786', 'author': 'Lu Yao', 'year': '2021', 'unstructured': 'Yao Lu , Max Bartolo , Alastair Moore , Sebastian Riedel , and Pontus Stenetorp . 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 ( 2021 ). https://arxiv.org/abs/2104.08786 Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity. ArXiv preprint abs/2104.08786 (2021). https://arxiv.org/abs/2104.08786'}, {'key': 'e_1_3_2_2_13_1', 'volume-title': 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773', 'author': 'Mishra Swaroop', 'year': '2021', 'unstructured': 'Swaroop Mishra , Daniel Khashabi , Chitta Baral , and Hannaneh Hajishirzi . 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 ( 2021 ). https://arxiv.org/abs/2104.08773 Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. ArXiv preprint abs/2104.08773 (2021). https://arxiv.org/abs/2104.08773'}, {'key': 'e_1_3_2_2_14_1', 'volume-title': 'Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).', 'author': 'Sculley D.', 'year': '2014', 'unstructured': 'D. Sculley , Gary Holt , Daniel Golovin , Eugene Davydov , Todd Phillips , Dietmar Ebner , Vinay Chaudhary , and Michael Young . 2014 . Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop). D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay Chaudhary, and Michael Young. 2014. Machine Learning: The High Interest Credit Card of Technical Debt. In SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop).'}, {'key': 'e_1_3_2_2_15_1', 'doi-asserted-by': 'publisher', 'DOI': '10.18653/v1/2021.eacl-demos.29'}, {'key': 'e_1_3_2_2_16_1', 'volume-title': 'LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239', 'author': 'Thoppilan Romal', 'year': '2022', 'unstructured': 'Romal Thoppilan , Daniel De\xa0Freitas , Jamie Hall , Noam Shazeer , Apoorv Kulshreshtha , Heng-Tze Cheng , Alicia Jin , Taylor Bos , Leslie Baker , Yu Du , 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 ( 2022 ). https://arxiv.org/abs/2201.08239 Romal Thoppilan, Daniel De\xa0Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, 2022. LaMDA: Language Models for Dialog Applications. ArXiv preprint abs/2201.08239 (2022). https://arxiv.org/abs/2201.08239'}, {'key': 'e_1_3_2_2_17_1', 'doi-asserted-by': 'publisher', 'DOI': '10.1145/3491102.3517582'}, {'key': 'e_1_3_2_2_18_1', 'volume-title': 'Association for Computing Machinery', 'author': 'Yang Qian', 'unstructured': 'Qian Yang , Aaron Steinfeld , Carolyn Rosé , and John Zimmerman . 2020. Re-Examining Whether , Why, and How Human-AI Interaction Is Uniquely Difficult to Design . Association for Computing Machinery , New York, NY, USA , 1–13. https://doi.org/10.1145/3313831.3376301 Qian Yang, Aaron Steinfeld, Carolyn Rosé, and John Zimmerman. 2020. Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design. Association for Computing Machinery, New York, NY, USA, 1–13. https://doi.org/10.1145/3313831.3376301'}], 'event': {'name': "CHI '22: CHI Conference on Human Factors in Computing Systems", 'location': 'New Orleans LA USA', 'acronym': "CHI '22", 'sponsor': ['SIGCHI ACM Special Interest Group on Computer-Human Interaction']}, 'container-title': ['CHI Conference on Human Factors in Computing Systems Extended Abstracts'], 'original-title': [], 'link': [{'URL': 'https://dl.acm.org/doi/pdf/10.1145/3491101.3519729', 'content-type': 'unspecified', 'content-version': 'vor', 'intended-application': 'similarity-checking'}], 'deposited': {'date-parts': [[2022, 5, 5]], 'date-time': '2022-05-05T00:55:49Z', 'timestamp': 1651712149000}, 'score': 1, 'resource': {'primary': {'URL': 'https://dl.acm.org/doi/10.1145/3491101.3519729'}}, 'subtitle': [], 'short-title': [], 'issued': {'date-parts': [[2022, 4, 27]]}, 'references-count': 17, 'alternative-id': ['10.1145/3491101.3519729', '10.1145/3491101'], 'URL': 'https://doi.org/10.1145/3491101.3519729', 'relation': {}, 'subject': [], 'published': {'date-parts': [[2022, 4, 27]]}, 'client_source': ['crossref', 'semantic_scholar'], 'paperId': '0f733817e82026f7c29909a51cb4df7d2685f0e7', 'externalIds': {'DBLP': 'journals/corr/abs-2203-06566', 'ArXiv': '2203.06566', 'DOI': '10.1145/3491101.3519729', 'CorpusId': 247447133}}, formatted_citation='Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.')), score=8)], references='1. (wu2022promptchainerchaininglarge pages 2-3): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n2. (wu2022promptchainerchaininglarge pages 1-1): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n3. (wu2022promptchainerchaininglarge pages 1-2): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n4. (wu2022promptchainerchaininglarge pages 4-5): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n5. (wu2022promptchainerchaininglarge pages 6-7): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.', formatted_answer='Question: What are the main challenges in question answering with scientific literature?\n\nQuestion answering with scientific literature presents several challenges, particularly when leveraging large language models (LLMs). One major issue is the need to decompose complex tasks into multiple sub-tasks, each requiring separate LLM prompts. This chaining approach increases transparency and control but introduces difficulties in designing and coordinating prompts, managing information flow between steps, and efficiently prototyping applications (wu2022promptchainerchaininglarge pages 1-2). \n\nErrors in one step can propagate through the chain, leading to cascading failures that hinder accurate results. Debugging such chains is particularly challenging due to the black-box nature of LLMs and the interdependencies between prompts (wu2022promptchainerchaininglarge pages 2-3, wu2022promptchainerchaininglarge pages 4-5). Additionally, maintaining logical consistency across interdependent tasks is difficult, especially when outputs from parallel tasks are not well-coordinated (wu2022promptchainerchaininglarge pages 6-7).\n\nUsers also face challenges in transforming data between steps, tracking how information flows through the chain, and mapping outputs back to original inputs. This complexity can overwhelm users, particularly non-experts, and necessitates tools for better tracing, visualization, and debugging (wu2022promptchainerchaininglarge pages 1-1, wu2022promptchainerchaininglarge pages 6-7). Tools like PromptChainer aim to address these issues by providing visual programming interfaces and features such as automated updates, unit testing, and breakpoint debugging (wu2022promptchainerchaininglarge pages 4-5).\n\nReferences\n\n1. (wu2022promptchainerchaininglarge pages 2-3): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n2. (wu2022promptchainerchaininglarge pages 1-1): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n3. (wu2022promptchainerchaininglarge pages 1-2): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n4. (wu2022promptchainerchaininglarge pages 4-5): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n\n5. (wu2022promptchainerchaininglarge pages 6-7): Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. Promptchainer: chaining large language model prompts through visual programming. CHI Conference on Human Factors in Computing Systems Extended Abstracts, Apr 2022. URL: https://doi.org/10.48550/arxiv.2203.06566, doi:10.48550/arxiv.2203.06566. This article has 87 citations.\n', graded_answer=None, cost=0.0538185, token_counts={'gpt-4o-2024-11-20': [6809, 483], 'gpt-4.1-2025-04-14': [10367, 1404]}, config_md5='c2d3871e0896fb4978bab71fc7a64da5', tool_history=[['paper_search'], ['paper_search'], ['paper_search'], ['gather_evidence'], ['gen_answer'], ['complete']], used_contexts={'wu2022promptchainerchaininglarge pages 1-1', 'wu2022promptchainerchaininglarge pages 2-3', 'wu2022promptchainerchaininglarge pages 4-5', 'wu2022promptchainerchaininglarge pages 6-7', 'wu2022promptchainerchaininglarge pages 1-2'}), bibtex=None, status=&lt;AgentStatus.SUCCESS: 'success'&gt;, timing_info=None, duration=0.0, stats=None)</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="using-the-agent-interface">Using the Agent Interface</h2>
<p>The above examples use the tools directly. You can also use the agent interface, which provides a more natural language experience.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="c1"># Use the agent interface to interact with the papers</span>
<span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">paperqa_agent</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="s2">&quot;What is Crispr? Add relevant papers&quot;</span><span class="p">,</span>
    <span class="n">deps</span><span class="o">=</span><span class="n">paperqa_config</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>I was unable to retrieve relevant information or papers about CRISPR at this time. You can consider providing me with a direct link to a paper if you have one, or specify more criteria to refine the search!
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="cleanup">Cleanup</h2>
<p>Let's clean up our temporary directory.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">shutil</span>
<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">temp_dir</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Temporary directory removed.&quot;</span><span class="p">)</span>
</code></pre></div>

</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="output_subarea output_stream output_stdout output_text">
<pre>
<code>Temporary directory removed.
</code>
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="running-the-paperqa-agent-ui">Running the PaperQA Agent UI</h2>
<p>The Aurelian framework provides a convenient way to launch the PaperQA agent as a Gradio UI. This allows you to interact with your papers through a chat interface.</p>
<p>To start the PaperQA agent UI from the command line, use:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Use the generic agent runner with the paperqa agent</span>
aurelian<span class="w"> </span>agent<span class="w"> </span>--agent<span class="w"> </span>paperqa<span class="w"> </span>--ui

<span class="c1"># Optional parameters:</span>
<span class="c1"># --workdir /path/to/papers    # Set a specific working directory</span>
<span class="c1"># --model gpt-3.5-turbo-0125   # Use a specific model (cheaper alternative)</span>
<span class="c1"># --share                      # Create a shareable link</span>
<span class="c1"># --server-port 7860           # Run on a specific port</span>
</code></pre></div>
<p>In the UI, you can:
- Search for papers: "Search for papers on CRISPR gene editing"
- Ask questions: "What are the main challenges in CRISPR gene editing?"
- Add papers: "Add this paper: https://example.com/paper.pdf"
- List papers: "Show me all the papers in the collection"
- Rebuild index: "Rebuild the search index"</p>
<p>The PaperQA agent will process your natural language requests and perform the corresponding actions.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="conclusion">Conclusion</h2>
<p>You've now seen how to use the Aurelian PaperQA integration to:
- Configure the agent with custom settings
- Add papers to your collection
- List papers in your collection
- Search for papers on specific topics
- Query papers to answer scientific questions</p>
<p>This integration makes it easy to work with scientific literature and extract insights from research papers.</p>
</div>
</div>
</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.tabs.link"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.56ea9cef.min.js"></script>
      
    
  </body>
</html>